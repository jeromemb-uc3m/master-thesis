{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CLEAN GADGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processes code lines by:\n",
    "\n",
    "- Replacing user-defined function names with symbolic names like `FUN1, FUN2`, etc.\n",
    "- Replacing user-defined variable names with symbolic names like `VAR1, VAR2`, etc.\n",
    "- Leaving keywords, built-in functions, and standard arguments (`argc, argv`) untouched.\n",
    "- Skipping over string and character literals, comments, and non-ASCII characters to focus only on code identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Immutable set of keywords up to C11 and C++17 standards.\n",
    "# These are reserved words in C/C++ that should not be renamed or replaced.\n",
    "keywords = frozenset({\n",
    "    '__asm', '__builtin', '__cdecl', '__declspec', '__except', '__export', '__far16', '__far32',\n",
    "    '__fastcall', '__finally', '__import', '__inline', '__int16', '__int32', '__int64', '__int8',\n",
    "    '__leave', '__optlink', '__packed', '__pascal', '__stdcall', '__system', '__thread', '__try',\n",
    "    '__unaligned', '_asm', '_Builtin', '_Cdecl', '_declspec', '_except', '_Export', '_Far16',\n",
    "    '_Far32', '_Fastcall', '_finally', '_Import', '_inline', '_int16', '_int32', '_int64',\n",
    "    '_int8', '_leave', '_Optlink', '_Packed', '_Pascal', '_stdcall', '_System', '_try', 'alignas',\n",
    "    'alignof', 'and', 'and_eq', 'asm', 'auto', 'bitand', 'bitor', 'bool', 'break', 'case',\n",
    "    'catch', 'char', 'char16_t', 'char32_t', 'class', 'compl', 'const', 'const_cast', 'constexpr',\n",
    "    'continue', 'decltype', 'default', 'delete', 'do', 'double', 'dynamic_cast', 'else', 'enum',\n",
    "    'explicit', 'export', 'extern', 'false', 'final', 'float', 'for', 'friend', 'goto', 'if',\n",
    "    'inline', 'int', 'long', 'mutable', 'namespace', 'new', 'noexcept', 'not', 'not_eq', 'nullptr',\n",
    "    'operator', 'or', 'or_eq', 'override', 'private', 'protected', 'public', 'register',\n",
    "    'reinterpret_cast', 'return', 'short', 'signed', 'sizeof', 'static', 'static_assert',\n",
    "    'static_cast', 'struct', 'switch', 'template', 'this', 'thread_local', 'throw', 'true', 'try',\n",
    "    'typedef', 'typeid', 'typename', 'union', 'unsigned', 'using', 'virtual', 'void', 'volatile',\n",
    "    'wchar_t', 'while', 'xor', 'xor_eq', 'NULL'\n",
    "})\n",
    "\n",
    "# Known, non-user-defined function names that shouldn't be replaced.\n",
    "main_set = frozenset({'main'})\n",
    "\n",
    "# Common arguments in the 'main' function that should not be renamed.\n",
    "main_args = frozenset({'argc', 'argv'})\n",
    "\n",
    "# Function to process and anonymize a C/C++ code snippet.\n",
    "# Input: gadget (list of strings), where each string is a line of code.\n",
    "# Output: cleaned_gadget (list of strings) with function/variable names replaced by symbolic names.\n",
    "def clean_gadget(gadget):\n",
    "    # Maps user-defined function names to anonymized symbols (e.g., FUN1, FUN2).\n",
    "    fun_symbols = {}\n",
    "\n",
    "    # Maps user-defined variable names to anonymized symbols (e.g., VAR1, VAR2).\n",
    "    var_symbols = {}\n",
    "\n",
    "    # Counters to generate unique symbolic names.\n",
    "    fun_count = 1\n",
    "    var_count = 1\n",
    "\n",
    "    # Regex to detect if a line is ending a multi-line comment.\n",
    "    rx_comment = re.compile(r'\\*/\\s*$')\n",
    "\n",
    "    # Regex to find candidate function names (words followed by an opening parenthesis).\n",
    "    rx_fun = re.compile(r'\\b([_A-Za-z]\\w*)\\b(?=\\s*\\()')\n",
    "\n",
    "    # Regex to find candidate variable names.\n",
    "    # Matches identifiers not immediately followed by a '('.\n",
    "    rx_var = re.compile(r'\\b([_A-Za-z]\\w*)\\b(?:(?=\\s*\\w+\\()|(?!\\s*\\w+))(?!\\s*\\()')\n",
    "\n",
    "    # List to store the cleaned code lines.\n",
    "    cleaned_gadget = []\n",
    "\n",
    "    # Process each line of the input gadget.\n",
    "    for line in gadget:\n",
    "        # Skip lines that end multi-line comments.\n",
    "        if rx_comment.search(line) is None:\n",
    "\n",
    "            # Step 1: Clean the line of literals and non-ASCII characters.\n",
    "\n",
    "            # Remove string literals (content inside double quotes) to avoid replacing names inside them.\n",
    "            nostrlit_line = re.sub(r'\".*?\"', '\"\"', line)\n",
    "\n",
    "            # Remove character literals (content inside single quotes).\n",
    "            nocharlit_line = re.sub(r\"'.*?'\", \"''\", nostrlit_line)\n",
    "\n",
    "            # Remove non-ASCII characters to ensure processing of clean ASCII text.\n",
    "            ascii_line = re.sub(r'[^\\x00-\\x7f]', r'', nocharlit_line)\n",
    "\n",
    "            # Step 2: Extract potential function and variable names.\n",
    "\n",
    "            # Find all function-like identifiers (names followed by '(').\n",
    "            user_fun = rx_fun.findall(ascii_line)\n",
    "\n",
    "            # Find all variable-like identifiers (names not followed by '(').\n",
    "            user_var = rx_var.findall(ascii_line)\n",
    "\n",
    "            # Step 3: Replace user-defined function names with symbolic names.\n",
    "            for fun_name in user_fun:\n",
    "                # Skip if it's 'main' or a reserved keyword.\n",
    "                if fun_name not in main_set and fun_name not in keywords:\n",
    "\n",
    "                    # If the function isn't already mapped, assign it a new symbol.\n",
    "                    if fun_name not in fun_symbols:\n",
    "                        fun_symbols[fun_name] = 'FUN' + str(fun_count)\n",
    "                        fun_count += 1\n",
    "\n",
    "                    # Replace function calls with the symbolic name (positive lookahead ensures it's only a function call).\n",
    "                    ascii_line = re.sub(\n",
    "                        r'\\b(' + re.escape(fun_name) + r')\\b(?=\\s*\\()',\n",
    "                        fun_symbols[fun_name],\n",
    "                        ascii_line\n",
    "                    )\n",
    "\n",
    "            # Step 4: Replace user-defined variable names with symbolic names.\n",
    "            for var_name in user_var:\n",
    "                # Skip if it's a reserved keyword or a common 'main' argument.\n",
    "                if var_name not in keywords and var_name not in main_args:\n",
    "\n",
    "                    # If the variable isn't already mapped, assign it a new symbol.\n",
    "                    if var_name not in var_symbols:\n",
    "                        var_symbols[var_name] = 'VAR' + str(var_count)\n",
    "                        var_count += 1\n",
    "\n",
    "                    # Replace variables with the symbolic name.\n",
    "                    # Uses lookaheads to ensure it's not a function name.\n",
    "                    ascii_line = re.sub(\n",
    "                        r'\\b(' + re.escape(var_name) + r')\\b(?:(?=\\s*\\w+\\()|(?!\\s*\\w+))(?!\\s*\\()',\n",
    "                        var_symbols[var_name],\n",
    "                        ascii_line\n",
    "                    )\n",
    "\n",
    "            # Append the processed line to the result list.\n",
    "            cleaned_gadget.append(ascii_line)\n",
    "\n",
    "    # Return the fully cleaned and anonymized code.\n",
    "    return cleaned_gadget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PARSE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(filename):\n",
    "    \"\"\"\n",
    "    Opens and reads the specified gadget file line by line.\n",
    "    Groups lines into individual gadgets, ignoring the first \"index\" line of each gadget.\n",
    "    Cleans each gadget using `clean_gadget()`, which anonymizes variable and function names.\n",
    "    Yields a tuple for each gadget: (cleaned_gadget_lines, gadget_label)\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\", encoding=\"utf8\") as file:\n",
    "        gadget = []       # Stores code lines for the current gadget\n",
    "        gadget_val = 0    # Stores the vulnerability label (0 or 1) for the current gadget\n",
    "        \n",
    "        for line in file:\n",
    "            stripped = line.strip()   # Remove leading/trailing whitespace\n",
    "            \n",
    "            if not stripped:\n",
    "                # Skip empty lines\n",
    "                continue\n",
    "\n",
    "            # Check for end-of-gadget delimiter (a line of dashes)\n",
    "            if \"-\" * 33 in line and gadget: \n",
    "                # Yield the current gadget and its label after cleaning it\n",
    "                yield clean_gadget(gadget), gadget_val\n",
    "                # Reset for the next gadget\n",
    "                gadget = []\n",
    "\n",
    "            # Check if the line starts with a digit (could be the label or code)\n",
    "            elif stripped.split()[0].isdigit():\n",
    "                if gadget:\n",
    "                    # If it's just a number, treat it as the vulnerability label (e.g., \"1\" or \"0\")\n",
    "                    if stripped.isdigit():\n",
    "                        gadget_val = int(stripped)\n",
    "                    else:\n",
    "                        # Otherwise, it's a code line that happens to start with a number\n",
    "                        gadget.append(stripped)\n",
    "            else:\n",
    "                # Regular code line, add it to the current gadget\n",
    "                gadget.append(stripped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object parse_file at 0x00000294C896A540>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"cwe399_cgd.txt\"\n",
    "parse_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = os.path.splitext(os.path.basename(filename))[0]\n",
    "vector_filename = base + \"_gadget_vectors.pkl\"\n",
    "vector_length = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. VECTORIZE GADGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a GadgetVectorizer class, which:\n",
    "\n",
    "- Tokenizes C/C++ code snippets (gadgets).\n",
    "- Trains a Word2Vec model on these tokenized gadgets.\n",
    "- Generates vector representations of gadgets using the trained Word2Vec embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import numpy\n",
    "\n",
    "# =======================\n",
    "# Operator Sets for Tokenization\n",
    "# =======================\n",
    "\n",
    "# Operators with 3 characters \n",
    "operators3 = {'<<=', '>>='}\n",
    "# Operators with 2 characters\n",
    "operators2 = {\n",
    "    '->', '++', '--', \n",
    "    '!~', '<<', '>>', '<=', '>=', \n",
    "    '==', '!=', '&&', '||', '+=', \n",
    "    '-=', '*=', '/=', '%=', '&=', '^=', '|='\n",
    "    }\n",
    "# Operators with 1 character\n",
    "operators1 = { \n",
    "    '(', ')', '[', ']', '.', \n",
    "    '+', '-', '*', '&', '/', \n",
    "    '%', '<', '>', '^', '|', \n",
    "    '=', ',', '?', ':' , ';',\n",
    "    '{', '}'\n",
    "    }\n",
    "\n",
    "\"\"\"\n",
    "A class for tokenizing code gadgets, training a Word2Vec model, and generating\n",
    "fixed-size vector representations of the gadgets.\n",
    "\n",
    "Primary Functions:\n",
    "- Tokenize individual code lines and gadgets.\n",
    "- Buffer gadgets and train Word2Vec embeddings.\n",
    "- Convert tokenized gadgets into 2D vector matrices.\n",
    "\n",
    "Each gadget is treated as a sequence of tokens, and the final vector\n",
    "representation is a matrix of size (50 x vector_length).\n",
    "\"\"\"\n",
    "class GadgetVectorizer:\n",
    "\n",
    "    def __init__(self, vector_length):\n",
    "        \"\"\"\n",
    "        Initialize the GadgetVectorizer.\n",
    "        \"\"\"\n",
    "        self.gadgets = []             # List to store tokenized gadgets for Word2Vec training.\n",
    "        self.vector_length = vector_length  # Dimension of each token vector.\n",
    "        self.forward_slices = 0       # Count of gadgets vectorized in forward direction.\n",
    "        self.backward_slices = 0      # Count of gadgets vectorized in backward direction.\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize(line):\n",
    "        \"\"\"\n",
    "        Tokenize a single line of C/C++ code.\n",
    "        Splits the line into tokens including identifiers, keywords, and operators.\n",
    "        Preserves the original order of tokens.\n",
    "        \"\"\"\n",
    "        tmp, w = [], []  # tmp: list of finalized tokens, w: characters building current word\n",
    "        i = 0\n",
    "\n",
    "        while i < len(line):\n",
    "            if line[i] == ' ':\n",
    "                # End of word; finalize and add a space token\n",
    "                tmp.append(''.join(w))\n",
    "                tmp.append(line[i])\n",
    "                w = []\n",
    "                i += 1\n",
    "            # Check for three-character operators (e.g., <<=)\n",
    "            elif line[i:i+3] in operators3:\n",
    "                tmp.append(''.join(w))\n",
    "                tmp.append(line[i:i+3])\n",
    "                w = []\n",
    "                i += 3\n",
    "            # Check for two-character operators (e.g., ++, ==)\n",
    "            elif line[i:i+2] in operators2:\n",
    "                tmp.append(''.join(w))\n",
    "                tmp.append(line[i:i+2])\n",
    "                w = []\n",
    "                i += 2\n",
    "            # Check for one-character operators (e.g., +, -, ;)\n",
    "            elif line[i] in operators1:\n",
    "                tmp.append(''.join(w))\n",
    "                tmp.append(line[i])\n",
    "                w = []\n",
    "                i += 1\n",
    "            else:\n",
    "                # Part of a word/identifier; collect characters\n",
    "                w.append(line[i])\n",
    "                i += 1\n",
    "\n",
    "        # Filter out empty strings and space tokens\n",
    "        res = list(filter(lambda c: c != '', tmp))\n",
    "        return list(filter(lambda c: c != ' ', res))\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize_gadget(gadget):\n",
    "        \"\"\"\n",
    "        Tokenize an entire gadget (list of code lines).\n",
    "\n",
    "        For each line:\n",
    "            - Tokenize the line.\n",
    "            - Concatenate all tokens into a single list.\n",
    "            - Check if any function calls (tokens starting with 'FUN') exist.\n",
    "        \"\"\"\n",
    "        tokenized = []\n",
    "        function_regex = re.compile(r'FUN(\\d)+')  # Matches tokens like FUN1, FUN2, etc.\n",
    "        backwards_slice = False\n",
    "\n",
    "        for line in gadget:\n",
    "            tokens = GadgetVectorizer.tokenize(line)\n",
    "            tokenized += tokens\n",
    "\n",
    "            # If a function token exists in this line, set backwards_slice to True\n",
    "            if any(function_regex.match(token) for token in tokens):\n",
    "                backwards_slice = True\n",
    "            else:\n",
    "                backwards_slice = False\n",
    "\n",
    "        return tokenized, backwards_slice\n",
    "\n",
    "    def add_gadget(self, gadget):\n",
    "        \"\"\"\n",
    "        Add a tokenized gadget to the training buffer.\n",
    "\n",
    "        Updates forward or backward slice counters depending on the presence of function tokens.\n",
    "        \"\"\"\n",
    "        tokenized_gadget, backwards_slice = GadgetVectorizer.tokenize_gadget(gadget)\n",
    "        self.gadgets.append(tokenized_gadget)\n",
    "        if backwards_slice:\n",
    "            self.backward_slices += 1\n",
    "        else:\n",
    "            self.forward_slices += 1\n",
    "\n",
    "    def vectorize(self, gadget):\n",
    "        \"\"\"\n",
    "        Generate a 2D vector representation of a gadget.\n",
    "\n",
    "        - Tokenizes the gadget.\n",
    "        - Creates a matrix of size (50 x vector_length).\n",
    "        - Fills it with token embeddings from the Word2Vec model.\n",
    "        - Uses forward or backward slicing to populate vectors.\n",
    "        \"\"\"\n",
    "        tokenized_gadget, backwards_slice = GadgetVectorizer.tokenize_gadget(gadget)\n",
    "        vectors = numpy.zeros(shape=(50, self.vector_length))\n",
    "\n",
    "        num_tokens = min(len(tokenized_gadget), 50)\n",
    "\n",
    "        if backwards_slice:\n",
    "            # Populate the matrix from the bottom up (reverse order)\n",
    "            for i in range(num_tokens):\n",
    "                token_index = len(tokenized_gadget) - 1 - i\n",
    "                vectors[49 - i] = self.embeddings[tokenized_gadget[token_index]]\n",
    "        else:\n",
    "            # Populate the matrix from the top down (forward order)\n",
    "            for i in range(num_tokens):\n",
    "                vectors[i] = self.embeddings[tokenized_gadget[i]]\n",
    "\n",
    "        return vectors\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "        Train the Word2Vec model on the buffered tokenized gadgets.\n",
    "\n",
    "        - Uses skip-gram model (`sg=1`) for learning embeddings.\n",
    "        - Sets `min_count=1` to ensure every token has an embedding.\n",
    "        - After training, keeps only the word vectors (embeddings).\n",
    "        - Frees memory by deleting the model and raw gadget data.\n",
    "        \"\"\"\n",
    "        # Train the Word2Vec model on all gadgets\n",
    "        model = Word2Vec(\n",
    "            sentences=self.gadgets,\n",
    "            min_count=1,\n",
    "            vector_size=self.vector_length,\n",
    "            sg=1  # Skip-gram model\n",
    "        )\n",
    "\n",
    "        # Save the learned word vectors\n",
    "        self.embeddings = model.wv\n",
    "\n",
    "        # Clean up to save memory\n",
    "        del model\n",
    "        del self.gadgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processes a gadget file and returns a DataFrame of vectorized gadgets and their labels.\n",
    "\n",
    "Workflow:\n",
    "---------\n",
    "1. Parse the gadget file using `parse_file()` to extract individual gadgets and their vulnerability labels.\n",
    "2. Store each gadget (code + label) in a list.\n",
    "3. Add each gadget to the `GadgetVectorizer` to build a training corpus.\n",
    "4. After all gadgets are collected, train a Word2Vec model on the tokens.\n",
    "5. Re-iterate over the gadgets and convert each into a fixed-size vector matrix.\n",
    "6. Store each vector and its corresponding label into a list.\n",
    "7. Convert the list into a Pandas DataFrame with two columns: \"vector\" and \"val\".\n",
    "\"\"\"\n",
    "def get_vectors_df(filename, vector_length=100):\n",
    "    gadgets = []  # List to hold all gadgets with their labels\n",
    "    count = 0\n",
    "    vectorizer = GadgetVectorizer(vector_length)  # Initialize vectorizer with embedding dimension\n",
    "\n",
    "    # First pass: parse and collect gadgets, add them to the vectorizer\n",
    "    for gadget, val in parse_file(filename):\n",
    "        count += 1\n",
    "        print(\"Collecting gadgets...\", count, end=\"\\r\")\n",
    "        vectorizer.add_gadget(gadget)  # Tokenize and store gadget for training\n",
    "        row = {\"gadget\": gadget, \"val\": val}  # Store raw gadget + label\n",
    "        gadgets.append(row)\n",
    "\n",
    "    # Print slicing mode stats\n",
    "    print('Found {} forward slices and {} backward slices'\n",
    "          .format(vectorizer.forward_slices, vectorizer.backward_slices))\n",
    "    print()\n",
    "\n",
    "    # Train Word2Vec model on all tokenized gadgets\n",
    "    print(\"Training model...\", end=\"\\r\")\n",
    "    vectorizer.train_model()\n",
    "    print()\n",
    "\n",
    "    vectors = []  # Final list to store vectorized gadgets\n",
    "    count = 0\n",
    "\n",
    "    # Second pass: convert each gadget to a vector\n",
    "    for gadget in gadgets:\n",
    "        count += 1\n",
    "        print(\"Processing gadgets...\", count, end=\"\\r\")\n",
    "        vector = vectorizer.vectorize(gadget[\"gadget\"])  # Get (50 x vector_length) matrix\n",
    "        row = {\"vector\": vector, \"val\": gadget[\"val\"]}  # Store vector + label\n",
    "        vectors.append(row)\n",
    "\n",
    "    print()\n",
    "\n",
    "    # Convert to DataFrame \n",
    "    df = pandas.DataFrame(vectors)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the preprocessed vector data already exists as a pickle file\n",
    "if os.path.exists(vector_filename):\n",
    "    # Load the DataFrame from the cached pickle file \n",
    "    df = pandas.read_pickle(vector_filename)\n",
    "else:\n",
    "    # If not cached, generate the vectors from the raw gadget file\n",
    "    df = get_vectors_df(filename, vector_length)\n",
    "    # Save the generated DataFrame as a pickle file for future reuse\n",
    "    df.to_pickle(vector_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BLSTM Hyperparameter Tuning using Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optuna works by sampling, training, and evaluating many model configurations.\n",
    "- It uses Bayesian optimization to intelligently choose hyperparameter values and finds the best set that maximizes validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import warnings\n",
    "import numpy as np\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional, LeakyReLU, ReLU\n",
    "from keras.optimizers import Adamax\n",
    "from keras.callbacks import EarlyStopping\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class BLSTM:\n",
    "    def __init__(self, data, name=\"blstm_optuna\"):\n",
    "        vectors = np.stack(data.iloc[:, 0].values)\n",
    "        labels = data.iloc[:, 1].values\n",
    "\n",
    "        # Show original distribution\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        print(f\"Original dataset class distribution: {dict(zip(unique, counts))}\")\n",
    "\n",
    "        # Split into train/test\n",
    "        X_train_raw, X_test, y_train_raw, y_test = train_test_split(\n",
    "            vectors, labels, test_size=0.2, stratify=labels, random_state=42\n",
    "        )\n",
    "\n",
    "        # Show pre-balanced training distribution\n",
    "        unique, counts = np.unique(y_train_raw, return_counts=True)\n",
    "        print(f\"Train split before balancing: {dict(zip(unique, counts))}\")\n",
    "\n",
    "        # Balance the training data\n",
    "        pos_idxs = np.where(y_train_raw == 1)[0]\n",
    "        neg_idxs = np.where(y_train_raw == 0)[0]\n",
    "        undersampled_neg_idxs = np.random.choice(neg_idxs, len(pos_idxs), replace=False)\n",
    "        balanced_idxs = np.concatenate([pos_idxs, undersampled_neg_idxs])\n",
    "        X_balanced = X_train_raw[balanced_idxs]\n",
    "        y_balanced = y_train_raw[balanced_idxs]\n",
    "\n",
    "        # Show post-balanced training distribution\n",
    "        unique, counts = np.unique(y_balanced, return_counts=True)\n",
    "        print(f\"Balanced training class distribution: {dict(zip(unique, counts))}\")\n",
    "\n",
    "        # Split into final train/val\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_balanced, y_balanced, test_size=0.2, stratify=y_balanced, random_state=42\n",
    "        )\n",
    "\n",
    "        print(f\"Final training class distribution: {dict(zip(*np.unique(y_train, return_counts=True)))}\")\n",
    "        print(f\"Validation class distribution: {dict(zip(*np.unique(y_val, return_counts=True)))}\")\n",
    "\n",
    "        self.X_train = X_train\n",
    "        self.X_val = X_val\n",
    "        self.X_test = X_test\n",
    "        self.y_train = to_categorical(y_train)\n",
    "        self.y_val = to_categorical(y_val)\n",
    "        self.y_test = to_categorical(y_test)\n",
    "        self.name = name\n",
    "\n",
    "        # Class weights from original training data (before balancing)\n",
    "        classes = np.unique(y_train_raw)\n",
    "        weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train_raw)\n",
    "        self.class_weight = dict(zip(classes, weights))\n",
    "\n",
    "    def build_model(self, trial):\n",
    "        model = Sequential()\n",
    "\n",
    "        lstm_units = trial.suggest_categorical('lstm_units', [192, 256])\n",
    "        dense_units_1 = trial.suggest_categorical('dense_units_1', [192, 256])\n",
    "        dense_units_2 = trial.suggest_categorical('dense_units_2', [192, 256])\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.30, 0.38)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 0.002, 0.0035, log=True)\n",
    "        activation_choice = trial.suggest_categorical('activation', ['LeakyReLU'])\n",
    "        batch_size = trial.suggest_categorical('batch_size', [64, 128])\n",
    "        epochs = trial.suggest_int('epochs', 8, 12)\n",
    "\n",
    "        model.add(Bidirectional(LSTM(lstm_units), input_shape=(self.X_train.shape[1], self.X_train.shape[2])))\n",
    "\n",
    "        model.add(Dense(dense_units_1))\n",
    "        model.add(LeakyReLU() if activation_choice == 'LeakyReLU' else ReLU())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "        model.add(Dense(dense_units_2))\n",
    "        model.add(LeakyReLU() if activation_choice == 'LeakyReLU' else ReLU())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "        model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "        optimizer = Adamax(learning_rate=learning_rate)\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        trial.set_user_attr('batch_size', batch_size)\n",
    "        trial.set_user_attr('epochs', epochs)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def objective(self, trial):\n",
    "        model = self.build_model(trial)\n",
    "\n",
    "        batch_size = trial.user_attrs['batch_size']\n",
    "        epochs = trial.user_attrs['epochs']\n",
    "\n",
    "        pruning_cb = TFKerasPruningCallback(trial, 'val_accuracy')\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "        model.fit(\n",
    "            self.X_train,\n",
    "            self.y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            class_weight=self.class_weight,\n",
    "            validation_data=(self.X_val, self.y_val),\n",
    "            callbacks=[pruning_cb, early_stop],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        val_loss, val_accuracy = model.evaluate(self.X_val, self.y_val, verbose=0)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        return val_accuracy\n",
    "\n",
    "    def run_optimization(self, n_trials=50, n_jobs=1):\n",
    "        study = optuna.create_study(direction='maximize', study_name=self.name)\n",
    "        study.optimize(self.objective, n_trials=n_trials, n_jobs=n_jobs)\n",
    "\n",
    "        print(\"Best trial:\")\n",
    "        trial = study.best_trial\n",
    "        print(f\"  Accuracy: {trial.value}\")\n",
    "        print(\"  Best hyperparameters:\")\n",
    "        for key, value in trial.params.items():\n",
    "            print(f\"    {key}: {value}\")\n",
    "\n",
    "        self.best_params = trial.params\n",
    "        self.model = self.build_model_with_params(self.best_params)\n",
    "        self.train_final_model()\n",
    "\n",
    "    def build_model_with_params(self, params):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Bidirectional(LSTM(params['lstm_units']), input_shape=(self.X_train.shape[1], self.X_train.shape[2])))\n",
    "\n",
    "        model.add(Dense(params['dense_units_1']))\n",
    "        model.add(LeakyReLU() if params['activation'] == 'LeakyReLU' else ReLU())\n",
    "        model.add(Dropout(params['dropout_rate']))\n",
    "\n",
    "        model.add(Dense(params['dense_units_2']))\n",
    "        model.add(LeakyReLU() if params['activation'] == 'LeakyReLU' else ReLU())\n",
    "        model.add(Dropout(params['dropout_rate']))\n",
    "\n",
    "        model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "        optimizer = Adamax(learning_rate=params['learning_rate'])\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train_final_model(self):\n",
    "        batch_size = self.best_params['batch_size']\n",
    "        epochs = self.best_params['epochs']\n",
    "\n",
    "        # Combine train and validation sets\n",
    "        X_full_train = np.concatenate([self.X_train, self.X_val], axis=0)\n",
    "        y_full_train = np.concatenate([self.y_train, self.y_val], axis=0)\n",
    "\n",
    "        # Rebuild model to reset weights\n",
    "        self.model = self.build_model_with_params(self.best_params)\n",
    "\n",
    "        early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "        self.model.fit(\n",
    "            X_full_train,\n",
    "            y_full_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            class_weight=self.class_weight,\n",
    "            validation_split=0.0,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        self.model.save_weights(self.name + \"_best_model.weights.h5\")\n",
    "\n",
    "    def test(self):\n",
    "        self.model.load_weights(self.name + \"_best_model.weights.h5\")\n",
    "\n",
    "        values = self.model.evaluate(self.X_test, self.y_test, batch_size=self.best_params['batch_size'], verbose=1)\n",
    "        print(\"Test Accuracy:\", values[1])\n",
    "\n",
    "        predictions = self.model.predict(self.X_test, batch_size=self.best_params['batch_size']).round()\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(\n",
    "            np.argmax(self.y_test, axis=1),\n",
    "            np.argmax(predictions, axis=1)\n",
    "        ).ravel()\n",
    "\n",
    "        print('False positive rate:', fp / (fp + tn))\n",
    "        print('False negative rate:', fn / (fn + tp))\n",
    "\n",
    "        recall = tp / (tp + fn)\n",
    "        precision = tp / (tp + fp)\n",
    "        f1_score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "        print('True positive rate (Recall):', recall)\n",
    "        print('Precision:', precision)\n",
    "        print('F1 score:', f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset class distribution: {0: 14600, 1: 7285}\n",
      "Train split before balancing: {0: 11680, 1: 5828}\n",
      "Balanced training class distribution: {0: 5828, 1: 5828}\n",
      "Final training class distribution: {0: 4662, 1: 4662}\n",
      "Validation class distribution: {0: 1166, 1: 1166}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-23 13:59:00,863] A new study created in memory with name: cwe399_cgd\n",
      "[I 2025-05-23 14:00:37,002] Trial 0 finished with value: 0.9249570965766907 and parameters: {'lstm_units': 192, 'dense_units_1': 192, 'dense_units_2': 192, 'dropout_rate': 0.3039637249738407, 'learning_rate': 0.0029976023618403544, 'activation': 'LeakyReLU', 'batch_size': 128, 'epochs': 12}. Best is trial 0 with value: 0.9249570965766907.\n",
      "[I 2025-05-23 14:02:17,695] Trial 1 finished with value: 0.9296740889549255 and parameters: {'lstm_units': 256, 'dense_units_1': 192, 'dense_units_2': 192, 'dropout_rate': 0.35211765305639636, 'learning_rate': 0.002652879992556034, 'activation': 'LeakyReLU', 'batch_size': 128, 'epochs': 12}. Best is trial 1 with value: 0.9296740889549255.\n",
      "[I 2025-05-23 14:04:14,566] Trial 2 finished with value: 0.9275299906730652 and parameters: {'lstm_units': 256, 'dense_units_1': 256, 'dense_units_2': 192, 'dropout_rate': 0.3592788656688265, 'learning_rate': 0.003382437112364196, 'activation': 'LeakyReLU', 'batch_size': 64, 'epochs': 12}. Best is trial 1 with value: 0.9296740889549255.\n",
      "[I 2025-05-23 14:05:27,746] Trial 3 finished with value: 0.9266723990440369 and parameters: {'lstm_units': 192, 'dense_units_1': 256, 'dense_units_2': 256, 'dropout_rate': 0.3496207509864972, 'learning_rate': 0.0020217345350494595, 'activation': 'LeakyReLU', 'batch_size': 64, 'epochs': 9}. Best is trial 1 with value: 0.9296740889549255.\n",
      "[I 2025-05-23 14:07:33,407] Trial 4 finished with value: 0.9331046342849731 and parameters: {'lstm_units': 256, 'dense_units_1': 256, 'dense_units_2': 256, 'dropout_rate': 0.31948108235856754, 'learning_rate': 0.0022742445991311092, 'activation': 'LeakyReLU', 'batch_size': 64, 'epochs': 12}. Best is trial 4 with value: 0.9331046342849731.\n",
      "[I 2025-05-23 14:07:44,830] Trial 5 pruned. Trial was pruned at epoch 0.\n",
      "[I 2025-05-23 14:07:54,820] Trial 6 pruned. Trial was pruned at epoch 0.\n",
      "[I 2025-05-23 14:08:27,276] Trial 7 pruned. Trial was pruned at epoch 2.\n",
      "[I 2025-05-23 14:08:41,152] Trial 8 pruned. Trial was pruned at epoch 0.\n",
      "[I 2025-05-23 14:08:56,829] Trial 9 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Accuracy: 0.9331046342849731\n",
      "  Best hyperparameters:\n",
      "    lstm_units: 256\n",
      "    dense_units_1: 256\n",
      "    dense_units_2: 256\n",
      "    dropout_rate: 0.31948108235856754\n",
      "    learning_rate: 0.0022742445991311092\n",
      "    activation: LeakyReLU\n",
      "    batch_size: 64\n",
      "    epochs: 12\n",
      "Epoch 1/12\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 63ms/step - accuracy: 0.6724 - loss: 0.5387\n",
      "Epoch 2/12\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.8818 - loss: 0.2752\n",
      "Epoch 3/12\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.8993 - loss: 0.2390\n",
      "Epoch 4/12\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - accuracy: 0.9029 - loss: 0.2169\n",
      "Epoch 5/12\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - accuracy: 0.9128 - loss: 0.1950\n",
      "Epoch 6/12\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9230 - loss: 0.1729\n",
      "Epoch 7/12\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9231 - loss: 0.1737\n",
      "Epoch 8/12\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9308 - loss: 0.1585\n",
      "Epoch 9/12\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9292 - loss: 0.1602\n",
      "Epoch 10/12\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - accuracy: 0.9338 - loss: 0.1501\n",
      "Epoch 11/12\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9297 - loss: 0.1532\n",
      "Epoch 12/12\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - accuracy: 0.9343 - loss: 0.1435\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9240 - loss: 0.1871\n",
      "Test Accuracy: 0.9234635829925537\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "False positive rate: 0.10034246575342466\n",
      "False negative rate: 0.028826355525051476\n",
      "True positive rate (Recall): 0.9711736444749485\n",
      "Precision: 0.8284543325526932\n",
      "F1 score: 0.8941548183254344\n"
     ]
    }
   ],
   "source": [
    "blstm = BLSTM(df,name=base)\n",
    "blstm.run_optimization(n_trials=10)\n",
    "blstm.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. THRESHOLD OPTIMIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal:\n",
    "To find the best classification threshold for a binary classification model (e.g., vulnerable vs. not vulnerable) by:\n",
    "\n",
    "- Predicting probabilities from a model.\n",
    "- Testing different thresholds (from 0.0 to 1.0).\n",
    "- Selecting the threshold that gives the highest F1 score.\n",
    "- Returning that optimal threshold and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def find_best_threshold_on_val(model, X_val, y_val, batch_size=128):\n",
    "    \"\"\"\n",
    "    Finds the optimal classification threshold using validation data.\n",
    "    \"\"\"\n",
    "    print(\"\\nSearching for optimal threshold using validation set...\")\n",
    "\n",
    "    probas = model.predict(X_val, batch_size=batch_size)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    positive_class_probs = probas[:, 1]\n",
    "\n",
    "    thresholds = np.arange(0.0, 1.01, 0.01)\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0\n",
    "\n",
    "    print(\"\\nThreshold\\tPrecision\\tRecall\\t\\tF1 Score\")\n",
    "    for th in thresholds:\n",
    "        preds = (positive_class_probs >= th).astype(int)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, preds, average='binary', zero_division=0\n",
    "        )\n",
    "        print(f\"{th:.2f}\\t\\t{precision:.4f}\\t\\t{recall:.4f}\\t\\t{f1:.4f}\")\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = th\n",
    "\n",
    "    print(f\"\\nBest threshold on validation set: {best_threshold:.2f} (F1 = {best_f1:.4f})\")\n",
    "    return best_threshold\n",
    "\n",
    "\n",
    "def evaluate_on_test(model, X_test, y_test, threshold, batch_size=128):\n",
    "    \"\"\"\n",
    "    Evaluates model performance on the test set using a fixed threshold.\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating on test set using threshold {threshold:.2f}...\")\n",
    "\n",
    "    probas = model.predict(X_test, batch_size=batch_size)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    preds = (probas[:, 1] >= threshold).astype(int)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, preds).ravel()\n",
    "\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    f1_score_final = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    accuracy = accuracy_score(y_true, preds)\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "    print(\"\\nFinal Test Evaluation:\")\n",
    "    print(f\"Test Accuracy: {accuracy:.6f}\")\n",
    "    print(f\"False positive rate: {fpr:.6f}\")\n",
    "    print(f\"False negative rate: {fnr:.6f}\")\n",
    "    print(f\"True positive rate (Recall): {recall:.6f}\")\n",
    "    print(f\"Precision: {precision:.6f}\")\n",
    "    print(f\"F1 score: {f1_score_final:.6f}\")\n",
    "\n",
    "    return {\n",
    "        'threshold': threshold,\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1': f1_score_final,\n",
    "        'fpr': fpr,\n",
    "        'fnr': fnr,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'tn': tn,\n",
    "        'fn': fn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for optimal threshold using validation set...\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "\n",
      "Threshold\tPrecision\tRecall\t\tF1 Score\n",
      "0.00\t\t0.5000\t\t1.0000\t\t0.6667\n",
      "0.01\t\t0.8041\t\t1.0000\t\t0.8914\n",
      "0.02\t\t0.8264\t\t1.0000\t\t0.9049\n",
      "0.03\t\t0.8382\t\t1.0000\t\t0.9120\n",
      "0.04\t\t0.8517\t\t1.0000\t\t0.9199\n",
      "0.05\t\t0.8567\t\t1.0000\t\t0.9228\n",
      "0.06\t\t0.8612\t\t1.0000\t\t0.9254\n",
      "0.07\t\t0.8650\t\t1.0000\t\t0.9276\n",
      "0.08\t\t0.8682\t\t1.0000\t\t0.9295\n",
      "0.09\t\t0.8708\t\t1.0000\t\t0.9309\n",
      "0.10\t\t0.8734\t\t1.0000\t\t0.9324\n",
      "0.11\t\t0.8741\t\t1.0000\t\t0.9328\n",
      "0.12\t\t0.8754\t\t1.0000\t\t0.9335\n",
      "0.13\t\t0.8767\t\t1.0000\t\t0.9343\n",
      "0.14\t\t0.8793\t\t1.0000\t\t0.9358\n",
      "0.15\t\t0.8792\t\t0.9991\t\t0.9354\n",
      "0.16\t\t0.8798\t\t0.9983\t\t0.9353\n",
      "0.17\t\t0.8818\t\t0.9983\t\t0.9364\n",
      "0.18\t\t0.8837\t\t0.9966\t\t0.9367\n",
      "0.19\t\t0.8891\t\t0.9966\t\t0.9397\n",
      "0.20\t\t0.8890\t\t0.9957\t\t0.9393\n",
      "0.21\t\t0.8888\t\t0.9940\t\t0.9385\n",
      "0.22\t\t0.8902\t\t0.9940\t\t0.9392\n",
      "0.23\t\t0.8915\t\t0.9940\t\t0.9400\n",
      "0.24\t\t0.8922\t\t0.9940\t\t0.9404\n",
      "0.25\t\t0.8922\t\t0.9940\t\t0.9404\n",
      "0.26\t\t0.8929\t\t0.9940\t\t0.9407\n",
      "0.27\t\t0.9087\t\t0.9897\t\t0.9475\n",
      "0.28\t\t0.9087\t\t0.9897\t\t0.9475\n",
      "0.29\t\t0.9137\t\t0.9897\t\t0.9502\n",
      "0.30\t\t0.9151\t\t0.9889\t\t0.9505\n",
      "0.31\t\t0.9158\t\t0.9889\t\t0.9509\n",
      "0.32\t\t0.9165\t\t0.9880\t\t0.9509\n",
      "0.33\t\t0.9171\t\t0.9871\t\t0.9508\n",
      "0.34\t\t0.9171\t\t0.9871\t\t0.9508\n",
      "0.35\t\t0.9186\t\t0.9871\t\t0.9516\n",
      "0.36\t\t0.9193\t\t0.9871\t\t0.9520\n",
      "0.37\t\t0.9201\t\t0.9871\t\t0.9524\n",
      "0.38\t\t0.9208\t\t0.9871\t\t0.9528\n",
      "0.39\t\t0.9215\t\t0.9871\t\t0.9532\n",
      "0.40\t\t0.9215\t\t0.9871\t\t0.9532\n",
      "0.41\t\t0.9215\t\t0.9863\t\t0.9528\n",
      "0.42\t\t0.9215\t\t0.9863\t\t0.9528\n",
      "0.43\t\t0.9237\t\t0.9863\t\t0.9540\n",
      "0.44\t\t0.9244\t\t0.9863\t\t0.9544\n",
      "0.45\t\t0.9242\t\t0.9828\t\t0.9526\n",
      "0.46\t\t0.9242\t\t0.9828\t\t0.9526\n",
      "0.47\t\t0.9256\t\t0.9820\t\t0.9530\n",
      "0.48\t\t0.9256\t\t0.9820\t\t0.9530\n",
      "0.49\t\t0.9256\t\t0.9820\t\t0.9530\n",
      "0.50\t\t0.9279\t\t0.9820\t\t0.9542\n",
      "0.51\t\t0.9279\t\t0.9820\t\t0.9542\n",
      "0.52\t\t0.9279\t\t0.9820\t\t0.9542\n",
      "0.53\t\t0.9279\t\t0.9820\t\t0.9542\n",
      "0.54\t\t0.9278\t\t0.9803\t\t0.9533\n",
      "0.55\t\t0.9293\t\t0.9803\t\t0.9541\n",
      "0.56\t\t0.9300\t\t0.9803\t\t0.9545\n",
      "0.57\t\t0.9308\t\t0.9803\t\t0.9549\n",
      "0.58\t\t0.9307\t\t0.9794\t\t0.9545\n",
      "0.59\t\t0.9359\t\t0.9760\t\t0.9555\n",
      "0.60\t\t0.9366\t\t0.9751\t\t0.9555\n",
      "0.61\t\t0.9366\t\t0.9751\t\t0.9555\n",
      "0.62\t\t0.9365\t\t0.9743\t\t0.9550\n",
      "0.63\t\t0.9407\t\t0.9657\t\t0.9530\n",
      "0.64\t\t0.9412\t\t0.9614\t\t0.9512\n",
      "0.65\t\t0.9435\t\t0.9588\t\t0.9511\n",
      "0.66\t\t0.9450\t\t0.9580\t\t0.9514\n",
      "0.67\t\t0.9489\t\t0.9563\t\t0.9526\n",
      "0.68\t\t0.9488\t\t0.9545\t\t0.9517\n",
      "0.69\t\t0.9512\t\t0.9520\t\t0.9516\n",
      "0.70\t\t0.9528\t\t0.9520\t\t0.9524\n",
      "0.71\t\t0.9567\t\t0.9468\t\t0.9517\n",
      "0.72\t\t0.9588\t\t0.9391\t\t0.9489\n",
      "0.73\t\t0.9596\t\t0.9374\t\t0.9484\n",
      "0.74\t\t0.9612\t\t0.9340\t\t0.9474\n",
      "0.75\t\t0.9700\t\t0.9142\t\t0.9413\n",
      "0.76\t\t0.9716\t\t0.9108\t\t0.9402\n",
      "0.77\t\t0.9733\t\t0.9082\t\t0.9397\n",
      "0.78\t\t0.9733\t\t0.9082\t\t0.9397\n",
      "0.79\t\t0.9740\t\t0.9005\t\t0.9358\n",
      "0.80\t\t0.9749\t\t0.8979\t\t0.9348\n",
      "0.81\t\t0.9757\t\t0.8945\t\t0.9333\n",
      "0.82\t\t0.9765\t\t0.8928\t\t0.9328\n",
      "0.83\t\t0.9774\t\t0.8902\t\t0.9318\n",
      "0.84\t\t0.9772\t\t0.8834\t\t0.9279\n",
      "0.85\t\t0.9780\t\t0.8765\t\t0.9245\n",
      "0.86\t\t0.9797\t\t0.8696\t\t0.9214\n",
      "0.87\t\t0.9797\t\t0.8679\t\t0.9204\n",
      "0.88\t\t0.9796\t\t0.8645\t\t0.9185\n",
      "0.89\t\t0.9814\t\t0.8611\t\t0.9173\n",
      "0.90\t\t0.9824\t\t0.8593\t\t0.9167\n",
      "0.91\t\t0.9822\t\t0.8525\t\t0.9128\n",
      "0.92\t\t0.9829\t\t0.8396\t\t0.9056\n",
      "0.93\t\t0.9848\t\t0.8319\t\t0.9019\n",
      "0.94\t\t0.9866\t\t0.8225\t\t0.8971\n",
      "0.95\t\t0.9936\t\t0.7993\t\t0.8859\n",
      "0.96\t\t0.9956\t\t0.7847\t\t0.8777\n",
      "0.97\t\t0.9966\t\t0.7487\t\t0.8550\n",
      "0.98\t\t0.9975\t\t0.6818\t\t0.8100\n",
      "0.99\t\t1.0000\t\t0.5840\t\t0.7374\n",
      "1.00\t\t0.0000\t\t0.0000\t\t0.0000\n",
      "\n",
      "Best threshold on validation set: 0.59 (F1 = 0.9555)\n",
      "\n",
      "Evaluating on test set using threshold 0.59...\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step\n",
      "\n",
      "Final Test Evaluation:\n",
      "Test Accuracy: 0.925748\n",
      "False positive rate: 0.091781\n",
      "False negative rate: 0.039121\n",
      "True positive rate (Recall): 0.960879\n",
      "Precision: 0.839329\n",
      "F1 score: 0.896000\n",
      "\n",
      "Final Test Evaluation with Threshold 0.59:\n",
      "F1 Score: 0.8960\n",
      "Precision: 0.8393\n",
      "Recall: 0.9609\n",
      "Accuracy: 0.9257\n",
      "FPR: 0.0918\n",
      "FNR: 0.0391\n"
     ]
    }
   ],
   "source": [
    "# Load the best model weights saved during training\n",
    "blstm.model.load_weights(blstm.name + \"_best_model.weights.h5\")\n",
    "\n",
    "# Find best threshold on validation set\n",
    "best_threshold = find_best_threshold_on_val(\n",
    "    model=blstm.model,\n",
    "    X_val=blstm.X_val,\n",
    "    y_val=blstm.y_val,\n",
    "    batch_size=blstm.best_params['batch_size']\n",
    ")\n",
    "\n",
    "# Evaluate model on test set using the best threshold\n",
    "test_metrics = evaluate_on_test(\n",
    "    model=blstm.model,\n",
    "    X_test=blstm.X_test,\n",
    "    y_test=blstm.y_test,\n",
    "    threshold=best_threshold,\n",
    "    batch_size=blstm.best_params['batch_size']\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\nFinal Test Evaluation with Threshold {test_metrics['threshold']:.2f}:\")\n",
    "print(f\"F1 Score: {test_metrics['f1']:.4f}\")\n",
    "print(f\"Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"FPR: {test_metrics['fpr']:.4f}\")\n",
    "print(f\"FNR: {test_metrics['fnr']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
